{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16UfAdui04OS_0bwNDvJOEQ_H4uJAObgI",
      "authorship_tag": "ABX9TyM9CWlzIZkerBbmfIUbeUJl"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow --quiet\n",
        "!pip install transformers --quiet"
      ],
      "metadata": {
        "id": "epWMFL3B3YaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714768d1-9045-464e-b1bc-d57021ba498f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6q76Pb9yALo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding,Dropout\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from gensim.models import FastText\n",
        "from gensim.models import KeyedVectors\n",
        "from keras.layers import Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv('PLCdata.csv',index_col= 0)\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Epxmfn_yOMV",
        "outputId": "4cc7d894-1bff-41fe-e66e-22ef92eb27dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1398 entries, 0 to 1397\n",
            "Data columns (total 5 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   Fault              1398 non-null   object\n",
            " 1   Diagnostic         1398 non-null   object\n",
            " 2   Corrective Action  1397 non-null   object\n",
            " 3   PLC                1398 non-null   object\n",
            " 4   Model              1398 non-null   object\n",
            "dtypes: object(5)\n",
            "memory usage: 65.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "JMNHdByMyUzn",
        "outputId": "f21f041b-55c5-4ba9-edc3-cb1af23fb9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Fault                         Diagnostic  \\\n",
              "0  cracked glass failure  broken or cracked glass electrode   \n",
              "1  cracked glass failure  broken or cracked glass electrode   \n",
              "2      zero offset error       reference electrode poisoned   \n",
              "3   high reference imped         coated reference electrode   \n",
              "4   high reference imped              sensor out of process   \n",
              "\n",
              "                                Corrective Action      PLC    Model  \n",
              "0                    replace electrode if cracked  emerson  model e  \n",
              "1                          check wiring for short  emerson  model e  \n",
              "2                    replace reference electorode  emerson  model e  \n",
              "3  clean electrode as instructed in sensor manual  emerson  model e  \n",
              "4  clean electrode as instructed in sensor manual  emerson  model e  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-471451e9-22ba-4fa2-aa48-778dcec24943\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fault</th>\n",
              "      <th>Diagnostic</th>\n",
              "      <th>Corrective Action</th>\n",
              "      <th>PLC</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cracked glass failure</td>\n",
              "      <td>broken or cracked glass electrode</td>\n",
              "      <td>replace electrode if cracked</td>\n",
              "      <td>emerson</td>\n",
              "      <td>model e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cracked glass failure</td>\n",
              "      <td>broken or cracked glass electrode</td>\n",
              "      <td>check wiring for short</td>\n",
              "      <td>emerson</td>\n",
              "      <td>model e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>zero offset error</td>\n",
              "      <td>reference electrode poisoned</td>\n",
              "      <td>replace reference electorode</td>\n",
              "      <td>emerson</td>\n",
              "      <td>model e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>high reference imped</td>\n",
              "      <td>coated reference electrode</td>\n",
              "      <td>clean electrode as instructed in sensor manual</td>\n",
              "      <td>emerson</td>\n",
              "      <td>model e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>high reference imped</td>\n",
              "      <td>sensor out of process</td>\n",
              "      <td>clean electrode as instructed in sensor manual</td>\n",
              "      <td>emerson</td>\n",
              "      <td>model e</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-471451e9-22ba-4fa2-aa48-778dcec24943')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-471451e9-22ba-4fa2-aa48-778dcec24943 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-471451e9-22ba-4fa2-aa48-778dcec24943');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_join = ['PLC', 'Model','Fault']\n",
        "\n",
        "df['input'] = df[columns_to_join].apply(lambda x: ' '.join(x), axis=1)\n",
        "df['input']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRdv5nuLypHm",
        "outputId": "36f13f86-2240-4a6b-f6d2-9c556d91e6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        emerson model e cracked glass failure\n",
              "1        emerson model e cracked glass failure\n",
              "2            emerson model e zero offset error\n",
              "3         emerson model e high reference imped\n",
              "4         emerson model e high reference imped\n",
              "                         ...                  \n",
              "1393           siemens logo bolock input error\n",
              "1394               siemens logo wiring problem\n",
              "1395               siemens logo wiring problem\n",
              "1396               siemens logo wiring problem\n",
              "1397    siemens logo as interface voltage fail\n",
              "Name: input, Length: 1398, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_join = ['Diagnostic','Corrective Action']\n",
        "\n",
        "df['output'] = df[columns_to_join].apply(lambda x: ', '.join(x.astype(str)), axis=1)\n",
        "df['output']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qIef1hB07aW",
        "outputId": "d3160c62-d226-42e9-fec3-4aa227c8f34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       broken or cracked glass electrode, replace ele...\n",
              "1       broken or cracked glass electrode, check wirin...\n",
              "2       reference electrode poisoned, replace referenc...\n",
              "3       coated reference electrode, clean electrode as...\n",
              "4       sensor out of process, clean electrode as inst...\n",
              "                              ...                        \n",
              "1393    insufficient memory space cannot add a block t...\n",
              "1394    physical cable connections from the end device...\n",
              "1395    there is no appropriate conductor crosssection...\n",
              "1396    cable length exceeds the specifications, make ...\n",
              "1397    communication between the logo system and the ...\n",
              "Name: output, Length: 1398, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_join = ['input','output']\n",
        "df['data'] = df[columns_to_join].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
        "df['data'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkXXWFFA0-BK",
        "outputId": "99c9d99e-2fb6-4e3f-df21-2a7d45095638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    emerson model e cracked glass failure broken o...\n",
              "1    emerson model e cracked glass failure broken o...\n",
              "2    emerson model e zero offset error reference el...\n",
              "3    emerson model e high reference imped coated re...\n",
              "4    emerson model e high reference imped sensor ou...\n",
              "Name: data, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def add_end_token(text):\n",
        "    text = re.sub(r'([^.]*\\.)', r'\\1 <end>', text)\n",
        "    text = text.strip().replace(' <end>', '<end>')\n",
        "    if not text.endswith('<end>'):\n",
        "        text += ' <end>'\n",
        "    return text\n",
        "\n",
        "df['data'] = df['data'].apply(add_end_token)"
      ],
      "metadata": {
        "id": "ivSqADJX2xWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df['data']\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data)\n",
        "sequences = tokenizer.texts_to_sequences(data)\n",
        "\n",
        "max_sequence_length = max([len(seq) for seq in sequences])\n",
        "input_data = []\n",
        "output_data = []\n",
        "for sequence in sequences:\n",
        "    for i in range(1, len(sequence)):\n",
        "        input_seq = sequence[:i]\n",
        "        input_seq = pad_sequences([input_seq], maxlen=max_sequence_length)[0]\n",
        "        output_seq = to_categorical(sequence[i], num_classes=len(tokenizer.word_index) + 1)\n",
        "        input_data.append(input_seq)\n",
        "        output_data.append(output_seq)\n",
        "input_data = np.array(input_data)\n",
        "output_data = np.array(output_data)\n",
        "\n",
        "fasttext = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/wiki-news-300d-1M.vec')\n",
        "\n",
        "embedding_dim = 300\n",
        "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in fasttext:\n",
        "        embedding_matrix[i] = fasttext[word]\n",
        "        \n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.word_index) + 1, embedding_dim, weights=[embedding_matrix], trainable=True))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(tokenizer.word_index) + 1, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3--i4qt27rx",
        "outputId": "5924f505-30a4-4fc6-db01-741bdbf8a37c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 300)         891600    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, None, 256)         570368    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, None, 256)         0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               197120    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2972)              383388    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,042,476\n",
            "Trainable params: 2,042,476\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/plc_lstm_12.h5')\n",
        "\n",
        "model.fit(input_data, output_data,batch_size=256, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_yE-Vn63iDV",
        "outputId": "291f1cc4-80c4-483c-dc40-440ec2fa62ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "196/196 [==============================] - 735s 4s/step - loss: 0.4661 - accuracy: 0.8911\n",
            "Epoch 2/5\n",
            "196/196 [==============================] - 741s 4s/step - loss: 0.4558 - accuracy: 0.8944\n",
            "Epoch 3/5\n",
            "196/196 [==============================] - 744s 4s/step - loss: 0.4495 - accuracy: 0.8948\n",
            "Epoch 4/5\n",
            "196/196 [==============================] - 739s 4s/step - loss: 0.4372 - accuracy: 0.8968\n",
            "Epoch 5/5\n",
            "196/196 [==============================] - 734s 4s/step - loss: 0.4339 - accuracy: 0.8988\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efbb0357520>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(input_data, output_data,batch_size=256, epochs=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LpVe_nK24sW",
        "outputId": "7d9ba861-5500-491e-fc20-733f7e7706bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "196/196 [==============================] - 737s 4s/step - loss: 0.4232 - accuracy: 0.8995\n",
            "Epoch 2/8\n",
            "196/196 [==============================] - 735s 4s/step - loss: 0.4216 - accuracy: 0.8993\n",
            "Epoch 3/8\n",
            "196/196 [==============================] - 737s 4s/step - loss: 0.4085 - accuracy: 0.9034\n",
            "Epoch 4/8\n",
            "196/196 [==============================] - 735s 4s/step - loss: 0.4033 - accuracy: 0.9030\n",
            "Epoch 5/8\n",
            "196/196 [==============================] - 738s 4s/step - loss: 0.3978 - accuracy: 0.9053\n",
            "Epoch 6/8\n",
            "196/196 [==============================] - 734s 4s/step - loss: 0.3929 - accuracy: 0.9060\n",
            "Epoch 7/8\n",
            "196/196 [==============================] - 739s 4s/step - loss: 0.3838 - accuracy: 0.9089\n",
            "Epoch 8/8\n",
            "196/196 [==============================] - 741s 4s/step - loss: 0.3847 - accuracy: 0.9078\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efbb0496950>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('plc_lstm_tokenizer.json', 'w') as f:\n",
        "    tokenizer_json = tokenizer.to_json()\n",
        "    json.dump(tokenizer_json, f)\n",
        "files.download('plc_lstm_tokenizer.json')\n"
      ],
      "metadata": {
        "id": "8huckOjIr97z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "model.save('plc_lstm_14_model.h5')\n",
        "files.download('plc_lstm_14_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "w3Q6GAkjiX75",
        "outputId": "e850e373-dc2b-4ef4-e785-ac072f6fd937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f7655a92-9104-4a8d-9297-6b720f8f81b6\", \"plc_lstm_14_model.h5\", 24559328)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from keras.preprocessing.text import tokenizer_from_json\n",
        "\n",
        "with open('/content/jsonformatter [MConverter.eu].json', 'r') as f:\n",
        "    json_string = f.read()\n",
        "\n",
        "tokenizer_json = json.loads(json_string)\n",
        "tokenizer= tokenizer_from_json(tokenizer_json)\n",
        "import keras\n",
        "model = keras.models.load_model(\"/content/plc_lstm_14_model.h5\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_TMGAdfgUFZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_text(model, tokenizer, input_text, max_length=40):\n",
        "    # initialize the generated output text with the input text\n",
        "    generated_text = input_text\n",
        "    # set the stop condition to False\n",
        "    stop_condition = False\n",
        "    while not stop_condition:\n",
        "        # tokenize the input texta\n",
        "        input_sequence = tokenizer.texts_to_sequences([generated_text])[0]\n",
        "        # pad the input sequence\n",
        "        input_sequence = pad_sequences([input_sequence], maxlen=max_length-1, padding='pre')\n",
        "        # make a prediction\n",
        "        prediction = model.predict(input_sequence)[0]\n",
        "        # get the index of the predicted word\n",
        "        predicted_index = np.argmax(prediction)\n",
        "        # get the predicted word\n",
        "        predicted_word = tokenizer.index_word.get(predicted_index, '')\n",
        "        # check if we've generated the maximum length or found the end token\n",
        "        if len(generated_text.split()) == max_length or predicted_word == 'end':\n",
        "            stop_condition = True\n",
        "        else:\n",
        "            # append the predicted word to the generated text\n",
        "            generated_text += ' ' + predicted_word\n",
        "    return generated_text[len(input_text):]"
      ],
      "metadata": {
        "id": "QgjNOqWiX2Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_text = 'emerson model e low input voltage'\n",
        "generated_text = generate_text(model, tokenizer, input_text)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "efAs1LHlWw19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8efa56fa-5b8f-43e9-8a5d-aff57a70db6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            " open connection from glass electrode to preamplifier check the connection between the glass electorode and preamplifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eeJqZkmR8L83"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}